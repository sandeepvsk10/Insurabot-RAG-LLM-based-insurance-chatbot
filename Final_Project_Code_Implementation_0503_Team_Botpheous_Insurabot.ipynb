{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Final Project - BUDT751 - Team Botpheus\n",
    "\n",
    "## Team Members\n",
    "- Sandeepkumar Vijaya Kumar\n",
    "- Nishok Ilangovan\n",
    "- Siddhesh Mishra\n",
    "- Tirth Shah\n",
    "- Rohit Anandhan\n",
    "- Srigugan Sivasubramani"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Meet Insura Bot\n",
    "\n",
    "**Meet InsuraBot - Your Intelligent Insurance Assistant**\n",
    "\n",
    "\n",
    "Introducing InsuraBot, your trusted companion for all things insurance-related. Designed to streamline your insurance inquiries and policy needs, InsuraBot is here to simplify the complex world of insurance and provide personalized assistance just for you.."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Leveraging 'RAG' (Retrieval-Augmented Generation) for the bot\n",
    "\n",
    "Certainly! Here's a short description leveraging the RAG architecture for the bot.\n",
    "\n",
    "InsuraBot employs the **RAG (Retrieval-Augmented Generation) architecture** , integrating **OpenAI's LLM**, (Large Language Model) based on the 3.5 version. It utilizes **FAISS for vector database management** and **OpenAI embeddings** for enhanced understanding. With LLM employing a **'similarity' retrieval mechanism**, fine-tuning is facilitated through PDF and CSV files. Additionally, **prompt engineering is optimized through template usage.** with **LangChain's chain** function orchestrating seamless integration and communication among the components..\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Why we choose RAG over Fine Tuning OpenAI Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Insurabot Architecture Diagram\n",
    "\n",
    "<img src=\"https://github.com/SandeepKamakaze/insurabot/blob/main/insurabot_architecture.png?raw=true\" width=80%>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implementation\n",
    "\n",
    "We have five steps for the implementation\n",
    "\n",
    "- Setting up environment for LLM, Vector DB and Data Loading\n",
    "- Loading the data\n",
    "- Managing storage of vectors and chat history\n",
    "- Prompt Engineering\n",
    "- LangChain Chain "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing Necessary Libraries for the RAG Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: langchain==0.1.16 in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (0.1.16)\n",
      "Requirement already satisfied: PyYAML>=5.3 in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from langchain==0.1.16) (6.0)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from langchain==0.1.16) (1.4.39)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from langchain==0.1.16) (3.8.3)\n",
      "Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from langchain==0.1.16) (0.6.5)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from langchain==0.1.16) (1.33)\n",
      "Requirement already satisfied: langchain-community<0.1,>=0.0.32 in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from langchain==0.1.16) (0.0.36)\n",
      "Requirement already satisfied: langchain-core<0.2.0,>=0.1.42 in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from langchain==0.1.16) (0.1.50)\n",
      "Requirement already satisfied: langchain-text-splitters<0.1,>=0.0.1 in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from langchain==0.1.16) (0.0.1)\n",
      "Requirement already satisfied: langsmith<0.2.0,>=0.1.17 in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from langchain==0.1.16) (0.1.54)\n",
      "Requirement already satisfied: numpy<2,>=1 in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from langchain==0.1.16) (1.24.3)\n",
      "Requirement already satisfied: pydantic<3,>=1 in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from langchain==0.1.16) (1.10.12)\n",
      "Requirement already satisfied: requests<3,>=2 in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from langchain==0.1.16) (2.31.0)\n",
      "Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from langchain==0.1.16) (8.2.2)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.1.16) (22.1.0)\n",
      "Requirement already satisfied: charset-normalizer<3.0,>=2.0 in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.1.16) (2.0.4)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.1.16) (6.0.2)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.1.16) (4.0.2)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.1.16) (1.8.1)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.1.16) (1.3.3)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.1.16) (1.2.0)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from dataclasses-json<0.7,>=0.5.7->langchain==0.1.16) (3.21.2)\n",
      "Requirement already satisfied: typing-inspect<1,>=0.4.0 in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from dataclasses-json<0.7,>=0.5.7->langchain==0.1.16) (0.9.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from jsonpatch<2.0,>=1.33->langchain==0.1.16) (2.1)\n",
      "Requirement already satisfied: packaging<24.0,>=23.2 in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from langchain-core<0.2.0,>=0.1.42->langchain==0.1.16) (23.2)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from langsmith<0.2.0,>=0.1.17->langchain==0.1.16) (3.10.3)\n",
      "Requirement already satisfied: typing-extensions>=4.2.0 in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from pydantic<3,>=1->langchain==0.1.16) (4.9.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from requests<3,>=2->langchain==0.1.16) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from requests<3,>=2->langchain==0.1.16) (1.26.16)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from requests<3,>=2->langchain==0.1.16) (2024.2.2)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from SQLAlchemy<3,>=1.4->langchain==0.1.16) (3.0.3)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain==0.1.16) (0.4.3)\n",
      "Requirement already satisfied: pypdf==4.2.0 in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (4.2.0)\n",
      "Requirement already satisfied: langchain-openai in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (0.1.6)\n",
      "Requirement already satisfied: langchain-core<0.2.0,>=0.1.46 in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from langchain-openai) (0.1.50)\n",
      "Requirement already satisfied: openai<2.0.0,>=1.24.0 in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from langchain-openai) (1.25.2)\n",
      "Requirement already satisfied: tiktoken<1,>=0.5.2 in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from langchain-openai) (0.6.0)\n",
      "Requirement already satisfied: PyYAML>=5.3 in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from langchain-core<0.2.0,>=0.1.46->langchain-openai) (6.0)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from langchain-core<0.2.0,>=0.1.46->langchain-openai) (1.33)\n",
      "Requirement already satisfied: langsmith<0.2.0,>=0.1.0 in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from langchain-core<0.2.0,>=0.1.46->langchain-openai) (0.1.54)\n",
      "Requirement already satisfied: packaging<24.0,>=23.2 in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from langchain-core<0.2.0,>=0.1.46->langchain-openai) (23.2)\n",
      "Requirement already satisfied: pydantic<3,>=1 in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from langchain-core<0.2.0,>=0.1.46->langchain-openai) (1.10.12)\n",
      "Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from langchain-core<0.2.0,>=0.1.46->langchain-openai) (8.2.2)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from openai<2.0.0,>=1.24.0->langchain-openai) (3.5.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from openai<2.0.0,>=1.24.0->langchain-openai) (1.9.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from openai<2.0.0,>=1.24.0->langchain-openai) (0.25.2)\n",
      "Requirement already satisfied: sniffio in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from openai<2.0.0,>=1.24.0->langchain-openai) (1.3.0)\n",
      "Requirement already satisfied: tqdm>4 in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from openai<2.0.0,>=1.24.0->langchain-openai) (4.65.0)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.7 in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from openai<2.0.0,>=1.24.0->langchain-openai) (4.9.0)\n",
      "Requirement already satisfied: regex>=2022.1.18 in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from tiktoken<1,>=0.5.2->langchain-openai) (2022.7.9)\n",
      "Requirement already satisfied: requests>=2.26.0 in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from tiktoken<1,>=0.5.2->langchain-openai) (2.31.0)\n",
      "Requirement already satisfied: idna>=2.8 in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from anyio<5,>=3.5.0->openai<2.0.0,>=1.24.0->langchain-openai) (3.4)\n",
      "Requirement already satisfied: certifi in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from httpx<1,>=0.23.0->openai<2.0.0,>=1.24.0->langchain-openai) (2024.2.2)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from httpx<1,>=0.23.0->openai<2.0.0,>=1.24.0->langchain-openai) (1.0.2)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai<2.0.0,>=1.24.0->langchain-openai) (0.14.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.2.0,>=0.1.46->langchain-openai) (2.1)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from langsmith<0.2.0,>=0.1.0->langchain-core<0.2.0,>=0.1.46->langchain-openai) (3.10.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from requests>=2.26.0->tiktoken<1,>=0.5.2->langchain-openai) (2.0.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from requests>=2.26.0->tiktoken<1,>=0.5.2->langchain-openai) (1.26.16)\n",
      "Requirement already satisfied: colorama in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from tqdm>4->openai<2.0.0,>=1.24.0->langchain-openai) (0.4.6)\n",
      "Requirement already satisfied: faiss-cpu in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (1.8.0)\n",
      "Requirement already satisfied: numpy in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from faiss-cpu) (1.24.3)\n"
     ]
    }
   ],
   "source": [
    "!pip install langchain==0.1.16\n",
    "!pip install pypdf==4.2.0\n",
    "!pip install -U langchain-openai\n",
    "!pip install faiss-cpu"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. `langchain==0.1.16`: This library provides a framework for orchestrating and integrating various language-related tools and technologies, enabling streamlined development of natural language processing pipelines.\n",
    "\n",
    "2. `pypdf==4.2.0`: This library facilitates parsing and extracting information from PDF files, which may be used as a data source for training or fine-tuning natural language models.\n",
    "\n",
    "3. `langchain-openai`: This package extends LangChain's capabilities by integrating the OpenAI API, allowing seamless interaction with OpenAI's language models for tasks such as text generation and retrieval.\n",
    "\n",
    "4. `faiss-cpu`: This library implements efficient similarity search and clustering of dense vectors, commonly used for vector database management and retrieval tasks, such as those involved in natural language understanding and retrieval-based conversational systems."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "executionInfo": {
     "elapsed": 405,
     "status": "ok",
     "timestamp": 1713575653598,
     "user": {
      "displayName": "HARIKRISHNA DEV",
      "userId": "02939311304673631641"
     },
     "user_tz": 300
    },
    "id": "DlTbo6xCEAt_"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from langchain.embeddings.openai import OpenAIEmbeddings\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.chains import ConversationalRetrievalChain\n",
    "from langchain.document_loaders.csv_loader import CSVLoader\n",
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "from langchain.vectorstores import FAISS\n",
    "from langchain.prompts import load_prompt\n",
    "\n",
    "import json\n",
    "import time\n",
    "import datetime\n",
    "import pypdf\n",
    "from pprint import pprint"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setting up environment for LLM, Vector DB and Data Loading"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Paths for prompt template, vector DB, Data Sources"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "executionInfo": {
     "elapsed": 2,
     "status": "ok",
     "timestamp": 1713576207776,
     "user": {
      "displayName": "HARIKRISHNA DEV",
      "userId": "02939311304673631641"
     },
     "user_tz": 300
    },
    "id": "2G1nfnlbE6l3"
   },
   "outputs": [],
   "source": [
    "prompt_template = \"template_insurance.json\"\n",
    "faiss_index = \"faiss_vector_store\"\n",
    "pdf_source = \"Home_insurance_sample.pdf\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. `prompt_template = \"template_default.json\"`: This parameter specifies the JSON file containing a template for prompt engineering. By allowing modification, it provides flexibility to change the response style of the bot, enabling adaptable and customizable interactions with users.\n",
    "\n",
    "2. `faiss_index = \"faiss_vector_store\"`: This parameter determines the folder location for storing the vector store created by FAISS. It can be customized to suit specific storage requirements or preferences, ensuring efficient management and retrieval of vector embeddings used in natural language processing tasks.\n",
    "\n",
    "3. `pdf_source = \"Home_insurance_sample.pdf\"`: This parameter specifies the location of text data stored in PDF format, which may contain unlabeled or unstructured information. It can be customized to use different PDF documents as a source of textual data, enabling the incorporation of diverse information sources into natural language processing pipelines."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setting Up OpenAI API Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 2,
     "status": "ok",
     "timestamp": 1713577079128,
     "user": {
      "displayName": "HARIKRISHNA DEV",
      "userId": "02939311304673631641"
     },
     "user_tz": 300
    },
    "id": "fHm_6br_IEqs"
   },
   "outputs": [],
   "source": [
    "os.environ['OPENAI_API_KEY'] = \"YOUR API KEY\"\n",
    "embeddings = OpenAIEmbeddings()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This sets the OpenAI API key as an environment variable using the `os.environ` dictionary. \n",
    "\n",
    "    \n",
    "Then, it imports the `OpenAIEmbeddings` class from the `langchain.embeddings` module. Finally, it initializes an instance of `OpenAIEmbeddings`. This instance can be used to access pre-trained embeddings provided by OpenAI for our text data / tokens\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setting Up Data Sources Loading Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "pdf_loader = PyPDFLoader(pdf_source)\n",
    "pdf_data = pdf_loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(pdf_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`PyPDFLoader`: Initializes a PDF loader (`PyPDFLoader`) to extract text data from the PDF file. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Domain Specific Data for the RAG Bot\n",
    "\n",
    "The PDF data for a sample home insurance is sourced from the website \"https://www.iii.org/\" ensuring compliance with ethical and legal standards. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(page_content='HOMEOWNERS\\nHO 00 03 10 00\\nHO 00 03 10 00 Copyright, Insurance Services Office, Inc., 1999 Page 1 of 22HOMEOWNERS 3 â€“ SPECIAL FORM\\nAGREEMENT\\nWe will provide the insurance described in this policy\\nin return for the premium and compliance with allapplicable provisions of this policy.\\nDEFINITIONS\\nA.In this policy, \"you\" and \"your\" refer to the \"named\\ninsured\" shown in the Declarations and the spouseif a resident of the same household. \"We\", \"us\"and \"our\" refer to the Company providing this in-surance.\\nB.In addition, certain words and phrases are definedas follows:\\n1.\"Aircraft Liability\", \"Hovercraft Liability\", \"Motor\\nVehicle Liability\" and \"Watercraft Liability\",subject to the provisions in b. below, mean the\\nfollowing:\\na.Liability for \"bodily injury\" or \"property dam-age\" arising out of the:\\n(1)Ownership of such vehicle or craft by an\"insured\";\\n(2)Maintenance, occupancy, operation,use, loading or unloading of such vehi-cle or craft by any person;\\n(3)Entrustment of such vehicle or craft byan \"insured\" to any person;\\n(4)Failure to supervise or negligent super-vision of any person involving such ve-hicle or craft by an \"insured\"; or\\n(5)Vicarious liability, whether or not im-posed by law, for the actions of a childor minor involving such vehicle or craft.\\nb.For the purpose of this definition:\\n(1)Aircraft means any contrivance used ordesigned for flight except model orhobby aircraft not used or designed tocarry people or cargo;\\n(2)Hovercraft means a self-propelled mo-torized ground effect vehicle and in-cludes, but is not limited to, flarecraftand air cushion vehicles;\\n(3)Watercraft means a craft principallydesigned to be propelled on or in waterby wind, engine power or electric motor;and\\n(4)Motor vehicle means a \"motor vehicle\"as defined in 7. below.2.\"Bodily injury\" means bodily harm, sickness ordisease, including required care, loss of serv-ices and death that results.\\n3.\"Business\" means:\\na.A trade, profession or occupation engagedin on a full-time, part-time or occasional ba-sis; or\\nb.Any other activity engaged in for money orother compensation, except the following:\\n(1)One or more activities, not described in(2) through (4) below, for which no \"in-\\nsured\" receives more than $2,000 intotal compensation for the 12 monthsbefore the beginning of the policy pe-riod;\\n(2)Volunteer activities for which no moneyis received other than payment for ex-penses incurred to perform the activity;\\n(3)Providing home day care services forwhich no compensation is received,other than the mutual exchange of suchservices; or\\n(4)The rendering of home day care serv-ices to a relative of an \"insured\".\\n4.\"Employee\" means an employee of an \"in-sured\", or an employee leased to an \"insured\"by a labor leasing firm under an agreementbetween an \"insured\" and the labor leasingfirm, whose duties are other than those per-formed by a \"residence employee\".\\n5.\"Insured\" means:\\na.You and residents of your household whoare:\\n(1)Your relatives; or\\n(2)Other persons under the age of 21 andin the care of any person named above;\\nb.A student enrolled in school full time, asdefined by the school, who was a residentof your household before moving out to at-tend school, provided the student is underthe age of:\\n(1)24 and your relative; or\\n(2)21 and in your care or the care of aperson described in a.(1) above; or\\n \\n \\n \\n \\n \\n \\nSAMPLE ', metadata={'source': 'Home_insurance_sample.pdf', 'page': 0}),\n",
       " Document(page_content='Page 2 of 22 Copyright, Insurance Services Office, Inc., 1999 HO 00 03 10 00c.Under Section II:\\n(1)With respect to animals or watercraft to\\nwhich this policy applies, any person or\\norganization legally responsible forthese animals or watercraft which areowned by you or any person included ina. or b. above. \"Insured\" does not mean\\na person or organization using or havingcustody of these animals or watercraft inthe course of any \"business\" or withoutconsent of the owner; or\\n(2)With respect to a \"motor vehicle\" towhich this policy applies:\\n(a)Persons while engaged in your em-ploy or that of any person included ina. or b. above; or\\n(b)Other persons using the vehicle onan \"insured location\" with your con-sent.\\nUnder both Sections  I and II, when the word an\\nimmediately precedes the word \"insured\", thewords an \"insured\" together mean one or more\"insureds\".\\n6.\"Insured location\" means:\\na.The \"residence premises\";\\nb.The part of other premises, other structuresand grounds used by you as a residence;and\\n(1)Which is shown in the Declarations; or\\n(2)Which is acquired by you during thepolicy period for your use as a resi-dence;\\nc.Any premises used by you in connectionwith a premises described in  a. and  b.\\nabove;\\nd.Any part of a premises:\\n(1)Not owned by an \"insured\"; and\\n(2)Where an \"insured\" is temporarily re-siding;\\ne.Vacant land, other than farm land, ownedby or rented to an \"insured\";\\nf.Land owned by or rented to an \"insured\" onwhich a one, two, three or four familydwelling is being built as a residence for an\"insured\";\\ng.Individual or family cemetery plots or burialvaults of an \"insured\"; orh.Any part of a premises occasionally rentedto an \"insured\" for other than \"business\"use.\\n7.\"Motor vehicle\" means:\\na.A self-propelled land or amphibious vehicle;or\\nb.Any trailer or semitrailer which is beingcarried on, towed by or hitched for towingby a vehicle described in a. above.\\n8.\"Occurrence\" means an accident, includingcontinuous or repeated exposure to substan-tially the same general harmful conditions,which results, during the policy period, in:\\na.\"Bodily injury\"; or\\nb.\"Property damage\".\\n9.\"Property damage\" means physical injury to,destruction of, or loss of use of tangible prop-erty.\\n10.\"Residence employee\" means:\\na.An employee of an \"insured\", or an em-ployee leased to an \"insured\" by a laborleasing firm, under an agreement betweenan \"insured\" and the labor leasing firm,whose duties are related to the mainte-nance or use of the \"residence premises\",including household or domestic services;or\\nb.One who performs similar duties elsewhere\\nnot related to the \"business\" of an \"in-sured\".\\nA \"residence employee\" does not include atemporary employee who is furnished to an\"insured\" to substitute for a permanent \"resi-dence employee\" on leave or to meet seasonalor short-term workload conditions.\\n11.\"Residence premises\" means:\\na.The one family dwelling where you reside;\\nb.The two, three or four family dwelling whereyou reside in at least one of the family units;or\\nc.That part of any other building where youreside;\\nand which is shown as the \"residence prem-ises\" in the Declarations.\\n\"Residence premises\" also includes other\\nstructures and grounds at that location.\\n \\n \\n \\n \\n \\n \\nSAMPLE ', metadata={'source': 'Home_insurance_sample.pdf', 'page': 1})]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pdf_data[:2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Managing storage of vectors and chat history"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Embedding Data & Storage of vector data into Vector Store (Using FAISS -Facebook AI Similarity Search )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 418
    },
    "executionInfo": {
     "elapsed": 3132,
     "status": "error",
     "timestamp": 1713577084981,
     "user": {
      "displayName": "HARIKRISHNA DEV",
      "userId": "02939311304673631641"
     },
     "user_tz": 300
    },
    "id": "SkFwq0vlICXN",
    "outputId": "d6344c7f-a9a3-454c-9986-2802543098eb"
   },
   "outputs": [],
   "source": [
    "data = pdf_data\n",
    "\n",
    "# Create embeddings for the docs\n",
    "vectors = FAISS.from_documents(data, embeddings)\n",
    "vectors.save_local(\"faiss_vector_store\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting Up Chat History"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "chat_history = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting up Conversational Retrieval Chain using LangChain\n",
    "\n",
    "In this process, a Conversational Retrieval Chain is established using LangChain libraries. Integration is performed between an OpenAI Chat model and a document retriever, facilitated by the `ConversationalRetrievalChain.from_llm()` function. This enables contextually relevant responses based on retrieved documents. Utilizing LangChain ensures streamlined integration and communication among the components, enhancing efficiency and effectiveness in developing conversational AI systems. This setup enhances conversational interactions by providing informative and contextually rich responses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "openai_api_key = os.getenv(\"OPENAI_API_KEY\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Choosing the desired Template for Prompt Engineering\n",
    "\n",
    "We employ various prompt templates to generate responses in different styles according to the user's preference. These prompts are integrated into LangChain's chain during response retrieval. \n",
    "\n",
    "The `combine_docs_chain_kwargs` parameter in the chain function facilitates this process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = load_prompt(prompt_template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'_type': 'prompt',\n",
      " 'input_variables': ['context', 'question'],\n",
      " 'template': 'System: You are a chatbot for home insurance company. You need '\n",
      "             'to provide responses to users who prompts insurance questions to '\n",
      "             'you. Be polite and provide answers based on the provided context '\n",
      "             'and chat_history only. Use only the provided data and not prior '\n",
      "             'knowledge. \\n'\n",
      "             ' Human: Take a deep breath and do the following step by step: \\n'\n",
      "             ' 1. Read the context and chat_history below \\n'\n",
      "             ' 2. Answer the question with detail using the provided Insurance '\n",
      "             'information \\n'\n",
      "             ' 3. If a user question seem like it requires previous prompts or '\n",
      "             'the responses, make sure the user question can be answered from '\n",
      "             'chat history first and then go to context. \\n'\n",
      "             ' 4. Make sure to nicely format the output in a three paragraph '\n",
      "             'answer and try to incorporate the STAR format. \\n'\n",
      "             '. Context : \\n'\n",
      "             ' ~~~ {context} ~~~ \\n'\n",
      "             ' User Question: --- {question} --- \\n'\n",
      "             '  chat_history: \\n'\n",
      "             ' ~~~ {chat_history} ~~~ \\n'\n",
      "             ' If a question is directed at you, clarify that you are merly a '\n",
      "             'bot and proceed to answer as if the question werw addressed to '\n",
      "             'insurance company. If you lack the necessary information to '\n",
      "             \"respond, simply state that you don't know; do not fabricate an \"\n",
      "             \"answer. If a query isn't related to the insurance policy, \"\n",
      "             'request the user to as questions related to the insurance and '\n",
      "             \"provide them the url 'www.sampleinsurance.com' . When \"\n",
      "             'responding, aim for detail but limit your answer to a maximum of '\n",
      "             '150 words. Ensure your response is formatted for easy reading. '\n",
      "             'Your output should be in a json format with 3 keys: answered - '\n",
      "             'type boolean, response - markdown of your answer. Ensure your '\n",
      "             'response is formatted for easy reading and please use only '\n",
      "             'context and chat_history to answer the question. \\n'\n",
      "             '\\n'\n",
      "             ' ```json'}\n"
     ]
    }
   ],
   "source": [
    "with open(prompt_template) as f:\n",
    "    prompt_data = json.load(f)\n",
    "pprint(prompt_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting up the Chain Function "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever = vectors.as_retriever(search_type=\"similarity\", search_kwargs={\"k\":6, \"include_metadata\":True, \"score_threshold\":0.6})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we create a vector retrieval function to specify the type of retriving mechanishm the LLM has to perform from the vector store. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "b-EoaLuXIXiK"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\LENOVO\\anaconda3\\Lib\\site-packages\\langchain_core\\_api\\deprecation.py:119: LangChainDeprecationWarning: The class `ChatOpenAI` was deprecated in LangChain 0.0.10 and will be removed in 0.2.0. An updated version of the class exists in the langchain-openai package and should be used instead. To use it run `pip install -U langchain-openai` and import as `from langchain_openai import ChatOpenAI`.\n",
      "  warn_deprecated(\n"
     ]
    }
   ],
   "source": [
    "chain = ConversationalRetrievalChain.from_llm(llm=ChatOpenAI(temperature=0.3,model_name='gpt-3.5-turbo', openai_api_key=openai_api_key), \n",
    "                                                retriever=retriever,return_source_documents=False,verbose=False,chain_type=\"stuff\",\n",
    "                                                max_tokens_limit=4097, combine_docs_chain_kwargs={\"prompt\": prompt})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, we create a chain function that takes a LLM for the generation, retrieval and incorporating context from its pre-trained neural network. \n",
    "\n",
    "- The Chain Function uses OpenAI LLM 'gpt-3.5-turbo'\n",
    "- This uses a similarity retreival as most of the RAG architectured bots do\n",
    "- The maximum tokens generated is also mentioned on top of providing the response structure during the prompt engineering.\n",
    "- The prompt template is also passed along that the LLM takes into consideration when retrieval and generating responses.\n",
    "                                                                    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_response(user_prompt):\n",
    "    result = chain({\n",
    "        \"system\": \"You are a chatbot for home insurance company. You need to provide responses to users who prompt insurance questions to you. Be polite and provide answers based on the provided context only. Use only the provided data and not prior knowledge.\", \n",
    "        \"question\": user_prompt,\n",
    "        \"chat_history\": chat_history\n",
    "    })\n",
    "    \n",
    "    chat_history.append((result[\"question\"], result[\"answer\"]))\n",
    "    print(\"\\nChatbot Response:\\n\")\n",
    "    print(json.loads(result[\"answer\"]).get(\"response\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# InsuraBot Functionality \n",
    "\n",
    "\"To test out the chatbot within the code, just replace the question in the function call to receive a relevant respons.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\LENOVO\\anaconda3\\Lib\\site-packages\\langchain_core\\_api\\deprecation.py:119: LangChainDeprecationWarning: The method `Chain.__call__` was deprecated in langchain 0.1.0 and will be removed in 0.2.0. Use invoke instead.\n",
      "  warn_deprecated(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Chatbot Response:\n",
      "\n",
      "The policy covers reasonable expenses for the removal of debris of covered property if a Peril Insured Against causes the loss. This expense is included in the limit of liability that applies to the damaged property. Additionally, the policy will also pay reasonable expenses for the removal of trees felled by specific perils, such as Windstorm or Hail. There is a limit of $1,000 for the removal of fallen trees, with no more than $500 being paid for the removal of any one tree.\n"
     ]
    }
   ],
   "source": [
    "get_response(\"What is the policy says about Debris Removal?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Chatbot Response:\n",
      "\n",
      "The policy provides coverage for the removal of fallen trees up to $1,000 for trees felled by perils like Windstorm or Hail. However, no more than $500 will be paid for the removal of any one tree. This additional insurance coverage ensures that the expenses for removing fallen trees are taken care of, offering financial support in such situations.\n"
     ]
    }
   ],
   "source": [
    "get_response(\"How much the policy give for damage of trees?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Chatbot Response:\n",
      "\n",
      "The insurance policy contains several exclusions to coverage. Some of the exclusions include losses caused by weather conditions if they contribute to an excluded cause, acts or decisions of individuals or organizations, and faulty planning, design, or maintenance of property. Additionally, intentional losses, governmental actions, and nuclear hazards are excluded from coverage. It's important to review the policy in detail to understand all the exclusions and limitations to ensure proper coverage.\n"
     ]
    }
   ],
   "source": [
    "get_response(\"What are the things that the insurance do not cover?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyPf0BZydq3VySoOSAWCke43",
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
